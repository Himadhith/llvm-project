; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py UTC_ARGS: --version 6
; RUN: llc -verify-machineinstrs -O3 -mcpu=pwr9 -mtriple=powerpc64le-unknown-linux-gnu \
; RUN:     -ppc-asm-full-reg-names --ppc-vsr-nums-as-vr < %s | FileCheck %s --check-prefix=POWERPC_64LE

; RUN: llc -verify-machineinstrs -O3 -mcpu=pwr9 -mtriple=powerpc64-ibm-aix \
; RUN:     -ppc-asm-full-reg-names --ppc-vsr-nums-as-vr < %s | FileCheck %s --check-prefix=POWERPC_64

; RUN: llc -verify-machineinstrs -O3 -mcpu=pwr9 -mtriple=powerpc-ibm-aix \
; RUN:     -ppc-asm-full-reg-names --ppc-vsr-nums-as-vr < %s | FileCheck %s --check-prefix=POWERPC_32

; Currently the generated code uses `vspltisw` to generate vector of 1s followed by add operation.
; This pattern is expected to be optimized in a future patch by using `xxleqv` to generate vector of -1s
; followed by subtraction operation.
define dso_local noundef <4 x i32> @test1(<4 x i32> %a) {
; POWERPC_64LE-LABEL: test1:
; POWERPC_64LE:       # %bb.0: # %entry
; POWERPC_64LE-NEXT:    vspltisw v3, 1
; POWERPC_64LE-NEXT:    vadduwm v2, v2, v3
; POWERPC_64LE-NEXT:    blr
;
; POWERPC_64-LABEL: test1:
; POWERPC_64:       # %bb.0: # %entry
; POWERPC_64-NEXT:    vspltisw v3, 1
; POWERPC_64-NEXT:    vadduwm v2, v2, v3
; POWERPC_64-NEXT:    blr
;
; POWERPC_32-LABEL: test1:
; POWERPC_32:       # %bb.0: # %entry
; POWERPC_32-NEXT:    vspltisw v3, 1
; POWERPC_32-NEXT:    vadduwm v2, v2, v3
; POWERPC_32-NEXT:    blr
entry:
  %add = add <4 x i32> %a, splat (i32 1)
  ret <4 x i32> %add
}
